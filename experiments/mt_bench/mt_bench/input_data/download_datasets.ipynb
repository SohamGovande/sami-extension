{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr/govande/miniconda3/envs/sami/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_math_data():\n",
    "    ds = load_dataset(\"lighteval/MATH\", \"all\")\n",
    "    objs = [{\"category\": \"math\", \"turns\": [x['problem']], 'reference': [x['solution']]} for i,x in enumerate(ds['train'])]\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roleplay_data():\n",
    "    ds = load_dataset(\"AlekseyKorshuk/roleplay-io\")\n",
    "    input_texts = ds['train']['input_text']\n",
    "    output_texts = ds['train']['output_text']\n",
    "    for i, text in enumerate(input_texts):\n",
    "        if text.startswith(\"User:\"):\n",
    "            text = text[len(\"User:\"):]\n",
    "        if text.endswith(\"Bot:\"):\n",
    "            text = text[:-len(\"Bot:\")]\n",
    "        input_texts[i] = text.strip()\n",
    "    for i, text in enumerate(output_texts):\n",
    "        if text.startswith(\"Bot:\"):\n",
    "            text = text[len(\"Bot:\"):]\n",
    "        if text.endswith(\"User:\"):\n",
    "            text = text[:-len(\"User:\")]\n",
    "        output_texts[i] = text.strip()\n",
    "    return [{'category': 'roleplay', 'turns': [x], 'reference': [output_texts[i]]} for i,x in enumerate(input_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coding_data():\n",
    "    ds = load_dataset(\"perlthoughts/coding-prompts-small\")\n",
    "    return [{'category': 'coding', 'turns': [x['instruction']], 'reference': []} for x in ds['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extraction_data():\n",
    "    ds = load_dataset(\"openai/summarize_from_feedback\", 'axis')['validation']\n",
    "    return [{'category': 'extraction', 'turns': f\"Extract the key points and summarize the following post: {x['post']}\",'reference': []}for x in ds['info']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Callable\n",
    "import random\n",
    "\n",
    "def build_training_data(functions: List[Callable], output_file_name: str):\n",
    "    data = []\n",
    "    for f in functions:\n",
    "        print('getting data from', f.__name__)\n",
    "        data.append(f())\n",
    "    cutoff_length = 3500\n",
    "    # min_length = min(len(d) for d in data) * 3\n",
    "    # min_length_function = functions[[len(d) for d in data].index(min_length)].__name__\n",
    "    # print('min_length', min_length, 'from function', min_length_function)\n",
    "    for i, d in enumerate(data):\n",
    "        filtered_data = []\n",
    "        for item in d:\n",
    "            prompt = item['turns'][0]\n",
    "            non_ascii_count = sum(1 for c in prompt if ord(c) > 127)\n",
    "            if non_ascii_count < 25:\n",
    "                filtered_data.append(item)\n",
    "            else:\n",
    "                print('removed item', item)\n",
    "        data[i] = filtered_data\n",
    "    \n",
    "    data = [d[:cutoff_length] for d in data]\n",
    "    data = [item for sublist in data for item in sublist]\n",
    "    random.shuffle(data)\n",
    "    print('shuffled!', data[:10])\n",
    "    for i, d in enumerate(data):\n",
    "        d['question_id'] = i\n",
    "    print('in total, we have', len(data), 'samples')\n",
    "    with open(f'{output_file_name}.json', 'w') as f:\n",
    "        content = \"\\n\".join([json.dumps(d) for d in data])\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ee_data():\n",
    "    ds = load_dataset(\"STEM-AI-mtl/Electrical-engineering\")['train']\n",
    "    return [{'category': 'stem', 'turns': [x['input']], 'reference': [x['output']]} for x in ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reasoning_data():\n",
    "    ds = load_dataset(\"reasoning-machines/gsm-hard\")['train']\n",
    "    return [{'category': 'coding', 'turns': [x['input'] + \" Write a python function to solve this problem. If you are instructed to, you may articulate your thought process in comments.\"], 'reference': [x['code']]} for x in ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_more_reasoning_data():\n",
    "    ds = load_dataset(\"livebench/reasoning\")['test']\n",
    "    ans = [{'category': 'reasoning', 'turns': [x['turns'][0]], 'reference': [x['ground_truth']]} for x in ds]\n",
    "    for x in ans:\n",
    "        for i, turn in enumerate(x['turns']):\n",
    "            x['turns'][i] = turn.split(\"Think step by step,\")[0]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_writing_data():\n",
    "    ds = load_dataset(\"allenai/WildChat-nontoxic\")['train']\n",
    "    print('loaded large chat dataset into memory')\n",
    "    ans = []\n",
    "    for x in ds:\n",
    "        ans.append({\n",
    "            'category': 'writing',\n",
    "            'turns': [x['conversation'][0]['content']],\n",
    "            'reference': [x['conversation'][1]['content']]\n",
    "        })\n",
    "        if len(ans) > 10000:\n",
    "            break\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_training_data([get_math_data, get_roleplay_data, get_coding_data, get_extraction_data, get_ee_data, get_reasoning_data, get_more_reasoning_data, get_writing_data], 'training_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sami",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
